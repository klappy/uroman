# Uroman Serverless - Multi-Cloud Architecture

Deploy uroman (universal romanizer) to any serverless platform using our unified architecture.

## ğŸ—ï¸ Architecture Overview

```
serverless/
â”œâ”€â”€ core/                    # Platform-agnostic business logic
â”‚   â”œâ”€â”€ romanizer_service.py # Core romanization service
â”‚   â”œâ”€â”€ handler.py          # HTTP request handler
â”‚   â””â”€â”€ mcp_handler.py      # MCP protocol handler
â”‚
â”œâ”€â”€ adapters/               # Platform-specific adapters
â”‚   â”œâ”€â”€ base_adapter.py     # Abstract base class
â”‚   â”œâ”€â”€ modal_adapter.py    # Modal.ai adapter
â”‚   â”œâ”€â”€ aws_lambda_adapter.py # AWS Lambda adapter
â”‚   â””â”€â”€ (more coming...)    # Cloudflare, Vercel, etc.
â”‚
â””â”€â”€ deployments/           # Platform-specific deployments
    â”œâ”€â”€ modal/            # Modal.ai deployment
    â”œâ”€â”€ aws/              # AWS Lambda deployment
    â””â”€â”€ (more coming...)  # Other platforms
```

## ğŸ¯ Design Principles

1. **Separation of Concerns**: Core logic is completely independent of deployment platform
2. **Adapter Pattern**: Each platform has its own adapter that translates platform-specific events
3. **Unified Interface**: Same API across all platforms
4. **Easy Extension**: Add new platforms by creating a new adapter

## ğŸš€ Quick Start

### Deploy to Modal.ai

```bash
cd serverless/deployments/modal
modal deploy deploy.py
```

### Deploy to AWS Lambda

```bash
cd serverless/deployments/aws
sam build
sam deploy --guided
```

### Deploy to Cloudflare Workers

```bash
cd serverless/deployments/cloudflare
wrangler deploy
```

## ğŸ”§ Adding a New Platform

1. Create a new adapter in `serverless/adapters/`:

```python
from .base_adapter import ServerlessAdapter

class YourPlatformAdapter(ServerlessAdapter):
    def handle_http_request(self, event, context):
        # Parse platform-specific event
        body = self.parse_your_platform_body(event)
        
        # Use unified handler
        result = self.handler.handle_request(body)
        
        # Return platform-specific response
        return self.create_http_response(200, result)
```

2. Create deployment configuration in `serverless/deployments/your-platform/`

3. Add tests in `serverless/tests/`

## ğŸ“¡ API Reference

All platforms expose the same API:

### Single Text Romanization
```json
POST /romanize
{
  "text": "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚ Ğ¼Ğ¸Ñ€",
  "lang_code": "rus"
}
```

### Batch Romanization
```json
POST /romanize
{
  "texts": ["Hello", "ĞŸÑ€Ğ¸Ğ²ĞµÑ‚", "ä½ å¥½"],
  "lang_code": null
}
```

### MCP Protocol (for AI assistants)
```json
POST /mcp
{
  "jsonrpc": "2.0",
  "method": "tools/list",
  "id": 1
}
```

## ğŸ§ª Testing

Run tests for all adapters:

```bash
cd serverless
python -m pytest tests/ -v
```

## ğŸ“Š Performance

- **Cold Start**: Varies by platform (Modal: 5-10s, AWS: 1-5s, Cloudflare: <1s)
- **Warm Response**: <100ms across all platforms
- **Memory Usage**: ~200MB (configurable per platform)

## ğŸ¤ Contributing

To add support for a new platform:

1. Create an adapter in `serverless/adapters/`
2. Add deployment configuration
3. Include tests
4. Update this README

## ğŸ“„ License

Same as uroman project - Apache 2.0
